# PyAudio setups
n_channel: 1
rate: 16000
chunk_size: 160
buffer_size: 4

# Misc
# root_path: /home/xianda/OneDrive/UC-Davis/Research Project/src
root_path: C:/OneDrive/UC-Davis/Research Project/src
file_name: DR5_MEGJ0_SA1
wav_path: ${root_path}/data/timit/train/${file_name}.WAV
phn_path: ${root_path}/data/timit/train/${file_name}.PHN
dataset_path: ${root_path}/data/timit

phn_reduction_dict_path: ./dicts/phoneme_39_dict.json
phn_idx_dict_path: ./dicts/phn_to_idx.json
phn_cat_dict_path: ./dicts/phn_cat_reduced.json

output_path: ./results
ckpt_path: ${output_path}/model_${run_name}.pt # path to a pre-trained model, if provided, training will resume from that point
report_path: ${output_path}/train_${run_name}.csv

# Execution setups
device: 'cuda'
device_id: 0
dev_run: False
dev_run_size: 50
re_train: True # if check point file exists, continue training on the saved model
run_name: 0 # run name

# Data processing parameters
num_workers: 8
batch_size: 32

n_mfcc: 13
n_fft: ${chunk_size}
hop_length: 80
n_mels: 40
n_classes: 39

# Training Hyper parameters
lr: 0.001 # initial learning rate
epochs: 10 # upper epoch limit
val_ratio: 0.1 # precentage of validation from train
loss_if_avg: True
true_label_weight: 0.8

# Model parameters
input_dim: 9

num_attention_head: 3

z_dim: 8
k_1_h: 4
k_1_w: 2
k_2_h: 4
k_2_w: 2

fc_1_input: 784
fc_1_hidden_1: 400
fc_1_hidden_2: 200

rnn_hidden: 400

fc_2_input: 400
fc_2_hidden_1: 200
fc_2_hidden_2: 100
fc_2_dropout: 0.3


